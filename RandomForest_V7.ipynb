{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import unwrap, diff, abs, angle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import hilbert\n",
    "from sklearn.utils import shuffle\n",
    "import scipy\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.interpolate import CubicSpline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import spectrogram\n",
    "from mne.viz import plot_topomap\n",
    "from scipy.signal import welch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import optuna\n",
    "from sklearn.datasets import make_classification\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from joblib import dump\n",
    "from scipy.signal import butter, filtfilt, lfilter, lfilter_zi\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#####################################################################################\n",
    "selected_columns = ['Fz', 'C3', 'Cz', 'C4', 'Pz', 'Po7', 'Oz', 'Po8']\n",
    "fs=250\n",
    "\n",
    "####################################################################################\n",
    "#pre/processing functions\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def detrend(df, col_names):\n",
    "    df_detrended = df.copy()\n",
    "    for col in col_names:\n",
    "        y = df_detrended[col]\n",
    "        x = np.arange(len(y))\n",
    "        p = np.polyfit(x, y, 1)\n",
    "        trend = np.polyval(p, x)\n",
    "        detrended = y - trend\n",
    "        df_detrended[col] = detrended\n",
    "    return df_detrended\n",
    "\n",
    "def denoise_data(df, col_names, n_clusters):\n",
    "    df_denoised = df.copy()\n",
    "    for col_name, k in zip(col_names, n_clusters):\n",
    "        df_denoised[col_name] = pd.to_numeric(df_denoised[col_name], errors='coerce') # Convert column to numeric format\n",
    "        X = df_denoised.select_dtypes(include=['float64', 'int64']) # Select only numeric columns\n",
    "        clf = KNeighborsRegressor(n_neighbors=k, weights='uniform') # Fit KNeighborsRegressor\n",
    "        clf.fit(X.index.values[:, np.newaxis], X[col_name])\n",
    "        y_pred = clf.predict(X.index.values[:, np.newaxis]) # Predict values \n",
    "        df_denoised[col_name] = y_pred\n",
    "    return df_denoised\n",
    "\n",
    "# def z_score(df, col_names):\n",
    "#     df_standard = df.copy()\n",
    "#     for col in col_names:\n",
    "#         df_standard[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "#     return df_standard\n",
    "\n",
    "def custom_detrend(df, col_names):\n",
    "    df_detrended = df.copy()\n",
    "    for col in col_names:\n",
    "        y = df_detrended[col]\n",
    "        x = np.arange(len(y))\n",
    "        p = np.polyfit(x, y, 1)\n",
    "        trend = np.polyval(p, x)\n",
    "        detrended = y - trend\n",
    "        df_detrended[col] = detrended\n",
    "    return df_detrended\n",
    "\n",
    "def preprocess(df, col_names, n_clusters):\n",
    "    df_new = df.copy()\n",
    "    df_new = denoise_data(df, col_names, n_clusters)\n",
    "    # df_new = z_score(df_new, col_names)\n",
    "    df_new = detrend(df_new, col_names)\n",
    "    return df_new\n",
    "\n",
    "def reject_artifacts(df, channel):\n",
    "    threshold_factor = 3\n",
    "    median = df[channel].median()\n",
    "    mad = np.median(np.abs(df[channel] - median))\n",
    "    spikes = np.abs(df[channel] - median) > threshold_factor * mad\n",
    "    x = np.arange(len(df[channel]))\n",
    "    cs = CubicSpline(x[~spikes], df[channel][~spikes]) # Interpolate using Cubic Spline\n",
    "    interpolated_values = cs(x)\n",
    "    interpolated_values[spikes] *= 0.01  # Make interpolated values 0.01 times smaller\n",
    "    # Again Check each interpolated value's difference from median and compare to the threshold\n",
    "    spike_values = np.abs(interpolated_values - median) > threshold_factor * mad\n",
    "    interpolated_values[spike_values] *= 0.01 \n",
    "    spike_values = np.abs(interpolated_values - median) > threshold_factor * mad\n",
    "    interpolated_values[spike_values] *= 0.01 \n",
    "    df[channel] = interpolated_values\n",
    "    return df\n",
    "\n",
    "#########################################################################################\n",
    "current_directory = os.getcwd()\n",
    "patient_data_folder = os.path.join(current_directory, \"1-Data_for_Model_Test\")\n",
    "\n",
    "folder_name = input(\"Please enter the subject name: \")\n",
    "Report_Number = input(\"Please enter the reprt number: \")\n",
    "full_folder_path = os.path.join(patient_data_folder, folder_name)\n",
    "\n",
    "# root_folder = \"2-Patient Data\"\n",
    "sub_folders = [\"Pre Evaluation\", \"Neurofeedback\", \"Post Evaluation\"]\n",
    "phase = int(input(\"Enter the phase (0, 1, 2): \"))  # Or however you get the phase value\n",
    "# Determine which sub-folders to use based on the phase\n",
    "folders_to_use = []\n",
    "if phase == 0:\n",
    "    folders_to_use = [sub_folders[0]]  # Just \"Pre Evaluation\"\n",
    "elif phase == 1:\n",
    "    folders_to_use = sub_folders[:2]  # \"Pre Evaluation\" and \"Neurofeedback\"\n",
    "elif phase == 2:\n",
    "    folders_to_use = [sub_folders[2]]  # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "#Notice that: base:2, face:0, scene:1\n",
    "duration = 40 \n",
    "raw=[]\n",
    "event=[]\n",
    "PP=[]\n",
    "Human_Behavior=[]\n",
    "eeg_processed=[]\n",
    "for folder in folders_to_use:\n",
    "    full_folder_path_ = os.path.join(full_folder_path, folder)\n",
    "    if os.path.exists(full_folder_path_) and os.path.isdir(full_folder_path_):\n",
    "        for file_name in os.listdir(full_folder_path_):\n",
    "            if file_name.endswith('.csv') and (file_name.startswith('raw_eeg_block') or file_name.startswith('fl_') \n",
    "                                               or file_name.startswith('R') or file_name.startswith('B')):\n",
    "                file_path = os.path.join(full_folder_path_, file_name)\n",
    "                s_temp = pd.read_csv(file_path, header=None)\n",
    "                \n",
    "                inst_symbol = s_temp.iloc[:, 17]\n",
    "                \n",
    "                #Converting the labels to numbers\n",
    "                inst=[]\n",
    "                for i in range(len(inst_symbol)):\n",
    "                    if 'g' in inst_symbol[i]  or 'b' in inst_symbol[i] :\n",
    "                        inst.append(2)\n",
    "                    if 'M' in inst_symbol[i]  or 'F' in inst_symbol[i] :\n",
    "                        inst.append(0)\n",
    "                    if 'O' in inst_symbol[i]  or 'I' in inst_symbol[i] :\n",
    "                        inst.append(1) \n",
    "                \n",
    "                HB=s_temp.iloc[1750:, 17:21]\n",
    "                df_temp_eeg = s_temp.iloc[:, :8]\n",
    "                Human_Behavior.append(HB)\n",
    "\n",
    "                # 1. Band Pass\n",
    "                raw_bp = np.copy(df_temp_eeg)\n",
    "                for column in range(8):\n",
    "                    raw_bp[:, column] = butter_bandpass_filter(raw_bp[:, column], lowcut=.4, highcut=40, fs=250) \n",
    "                \n",
    "                # 2. Artifact rejection\n",
    "                BP_artifact_RJ = np.copy(raw_bp)\n",
    "                for channel in range (8):\n",
    "                    BP_artifact_RJ= reject_artifacts(pd.DataFrame(BP_artifact_RJ), channel)\n",
    "                \n",
    "                # 3. Preprocessing: Denoise, Z-Score, Dtrend\n",
    "                BP_artifact_RJ.columns = selected_columns\n",
    "                eeg_df_denoised = preprocess(pd.DataFrame(BP_artifact_RJ), col_names=selected_columns, n_clusters=[10]*len(selected_columns))\n",
    "                \n",
    "                # I preprocessed the whole data in each block, then, split it to the base and the activity signal\n",
    "                eeg_activity=eeg_df_denoised.iloc[1750:,]                \n",
    "                \n",
    "                #concate the labels to the processed data\n",
    "                eeg_df_denoised_inst=pd.concat([eeg_df_denoised,pd.DataFrame(inst)], axis=1) \n",
    "                \n",
    "                eeg_processed.append(eeg_df_denoised_inst) #all blocks processes eeg with instruction containing both base and activity signal\n",
    "                #len(eeg_processed)= the number of blocks\n",
    "                PP.append(eeg_activity)\n",
    "    else:\n",
    "        print(f\"{full_folder_path_} does not exist\")\n",
    "        \n",
    "block_number=len(eeg_processed)\n",
    "print(block_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total_base_rejected_with_inst_np.shape: (24, 11750, 9) face_np.shape: (12, 11750, 9)\n"
     ]
    }
   ],
   "source": [
    "#baseline rejection\n",
    "activity_baserejected_with_inst=[]\n",
    "Total_base_rejected_with_inst=[]\n",
    "face=[] #label=0\n",
    "scene=[]#label=1, base label=2\n",
    "instruction_of_activity=[]\n",
    "event_=[]\n",
    "for i in range (len(eeg_processed)):\n",
    "    pp_data=eeg_processed[i]\n",
    "    instruction = pp_data.iloc[:, 8]\n",
    "\n",
    "    mask = pp_data.iloc[:, -1] == 2\n",
    "    baseline = pp_data[mask].iloc[:, :-1]\n",
    "    baseline_avg = baseline.mean()\n",
    "    activity_data = pp_data[~mask]\n",
    "\n",
    "    inst_activity=activity_data.iloc[:, 8]\n",
    "    instruction_of_activity.append(inst_activity)\n",
    "    \n",
    "    adjusted_activity = activity_data.iloc[:, :-1] - baseline_avg\n",
    "    adjusted_baseline = baseline - baseline_avg\n",
    "    \n",
    "    concatenated_base_activity = pd.concat([adjusted_baseline, adjusted_activity], ignore_index=True)\n",
    "    pp_data_baseline_rejected= pd.concat([concatenated_base_activity, instruction], axis=1) #both activity ans base with labels\n",
    "    \n",
    "    activity_baseline_rejected_with_inst= pd.concat([adjusted_activity, inst_activity], axis=1)\n",
    "    activity_baserejected_with_inst.append(activity_baseline_rejected_with_inst) #All the activity data and their labels\n",
    "    \n",
    "    Total_base_rejected_with_inst.append(pp_data_baseline_rejected) #All the data both activity ans base with labels\n",
    "    \n",
    "    # splitting the data to face and scene category\n",
    "    if [1] in instruction.values :\n",
    "        scene.append(pp_data_baseline_rejected) # has also the base            \n",
    "    if [0] in instruction.values :\n",
    "        face.append(pp_data_baseline_rejected)  # has also the base                       \n",
    "    event_.append(instruction) # has also the base   \n",
    "     \n",
    "face_np=np.array(face) # has also the base with labels\n",
    "scene_np=np.array(scene) # has also the base with labels\n",
    "event_np=np.array(event_)\n",
    "\n",
    "Total_base_rejected_with_inst_np=np.array(Total_base_rejected_with_inst) #All the data both activity ans base with labels\n",
    "print(' Total_base_rejected_with_inst_np.shape:', Total_base_rejected_with_inst_np.shape, 'face_np.shape:', face_np.shape)\n",
    "\n",
    "labels_np=np.array(instruction_of_activity)\n",
    "\n",
    "#epoching the labels\n",
    "label_final=labels_np.reshape(int(labels_np.shape[0]*labels_np.shape[1]/fs), fs)\n",
    "label_final_np=np.array(label_final)\n",
    "label_final_np_squeeze=np.squeeze(label_final_np[:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(df, col_names):\n",
    "    \n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for col in col_names:\n",
    "        mean_array=df[col].mean()\n",
    "        mean_list.append(mean_array)\n",
    "        std_array=df[col].std()\n",
    "        std_list.append(std_array)\n",
    "        # df_standard[col] = (df[col] - df[col].mean())/df[col].std()\n",
    "    return mean_list, std_list \n",
    "\n",
    "def apply_z_score(df, col_names, mean_list, std_list):\n",
    "    df_standard = df.copy()\n",
    "    for index, col in enumerate(col_names):\n",
    "        df_standard[col] = (df[col] - mean_list[index]) / std_list[index]\n",
    "    return df_standard\n",
    "\n",
    "input_z_score= Total_base_rejected_with_inst_np.reshape( Total_base_rejected_with_inst_np.shape[0]* Total_base_rejected_with_inst_np.shape[1],  Total_base_rejected_with_inst_np.shape[2])\n",
    "inst_zscore=input_z_score[:,-1]\n",
    "\n",
    "input_z_score_df = pd.DataFrame(input_z_score[:,:-1], columns=selected_columns)\n",
    "\n",
    "mean, std=z_score(input_z_score_df , col_names=selected_columns)\n",
    "z_scored_data = apply_z_score(input_z_score_df, selected_columns, mean, std)\n",
    "\n",
    "\n",
    "# Save to a DataFrame\n",
    "mean_std_df = pd.DataFrame({'Mean': mean, 'Std': std}, index=selected_columns)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "mean_std_df.to_csv('mean_std_values.csv')\n",
    "\n",
    "\n",
    "inst_zscore_2d=inst_zscore.reshape(inst_zscore.shape[0], 1)\n",
    "\n",
    "z_scored_data_np=np.array(z_scored_data)\n",
    "z_scored_data_np_inst=np.concatenate([z_scored_data_np, inst_zscore_2d], axis=1)\n",
    "z_scored_data_reshape_inst=z_scored_data_np_inst.reshape(Total_base_rejected_with_inst_np.shape[0], Total_base_rejected_with_inst_np.shape[1], Total_base_rejected_with_inst_np.shape[2])\n",
    "data_T =z_scored_data_reshape_inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wavelet\n",
    "#functions\n",
    "def morlet_wavelet(frequency, num_cycles, sampling_rate, duration=1):\n",
    "    t = np.linspace(-duration/2, duration/2, int(sampling_rate * duration), endpoint=False)\n",
    "    sine_wave = np.exp(2j * np.pi * frequency * t)\n",
    "    amplitude_envelope = np.exp(-t**2 * (np.pi * frequency / num_cycles)**2)\n",
    "    wavelet = sine_wave * amplitude_envelope\n",
    "    return wavelet\n",
    "\n",
    "def convolve_with_wavelet(data, wavelet):\n",
    "    # Ensure data is in 2D form\n",
    "    if data.ndim == 1:\n",
    "        data = data[np.newaxis, :]\n",
    "    n_signal = data.shape[1]\n",
    "    n_wavelet = len(wavelet)\n",
    "    n_convolution = n_signal + n_wavelet - 1\n",
    "\n",
    "    data_fft = np.fft.fft(data, n_convolution, axis=1)\n",
    "    wavelet_fft = np.fft.fft(wavelet, n_convolution)[np.newaxis, :]\n",
    "    convolution_result_fft = data_fft * wavelet_fft\n",
    "    convolution_result = np.fft.ifft(convolution_result_fft, axis=1)\n",
    "    # Cut the data\n",
    "    start = (n_wavelet - 1) // 2\n",
    "    end = start + n_signal\n",
    "    return convolution_result[:, start:end]\n",
    "####################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "frequencies = np.arange(0, 40, 1)  # 0 to 40 Hz\n",
    "cycles = np.linspace(.1,10, len(frequencies))  # Variable cycles from 1 to 10\n",
    "sampling_rate = 250\n",
    "selected_columns = ['Fz', 'C3', 'Cz', 'C4', 'Pz', 'Po7', 'Oz', 'Po8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 24, 40, 250)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Extraction\n",
    "#Wavelet\n",
    "####################################################################################################################################\n",
    "# Constants\n",
    "# frequencies = np.arange(0,40,1)  # 0 to 40 Hz\n",
    "# cycles = np.linspace(1, 8, len(frequencies))  # Variable cycles from 1 to 10\n",
    "# sampling_rate = 250\n",
    "selected_columns = ['Fz', 'C3', 'Cz', 'C4', 'Pz', 'Po7', 'Oz', 'Po8']\n",
    "data_T = Total_base_rejected_with_inst_np #shape: (32, 11750, 9)\n",
    "\n",
    "# Initialize a dictionary to store power matrices for each channel\n",
    "power_matrices_T = {channel: [] for channel in selected_columns}\n",
    "\n",
    "for channel_idx, channel_name in enumerate(selected_columns):\n",
    "    for freq, cycle in zip(frequencies, cycles):\n",
    "        power_blocks_base_corrected=[]\n",
    "        for i in range (len(data_T)): #8\n",
    "            data_T_i_np= data_T[i]\n",
    "            data_T_i_np_t=np.transpose(data_T_i_np)\n",
    "\n",
    "            # Extract one channel\n",
    "            data_T_i_t = data_T_i_np_t[channel_idx, :]  # Trials are on the second dimension\n",
    "            data_T_i_inst = data_T_i_np_t[8, :]\n",
    "            wavelet = morlet_wavelet(freq, cycle, sampling_rate)\n",
    "            convolution = convolve_with_wavelet(data_T_i_t , wavelet)    \n",
    "            power = np.abs(convolution)**2\n",
    "\n",
    "            data_T_i_inst_2d = data_T_i_inst[np.newaxis, :]\n",
    "            power_with_inst=np.concatenate([power,data_T_i_inst_2d], axis=0)\n",
    "            power_with_inst_t=np.transpose(power_with_inst)\n",
    "            mask = (power_with_inst_t[:, 1] == 2)\n",
    "            base_l= power_with_inst_t[mask]\n",
    "            base= base_l[:, :-1]\n",
    "            # print(base.shape)\n",
    "            mean_base= np.mean(base_l[:, :-1], axis=0)\n",
    "            # print('mean_base', mean_base)\n",
    "            \n",
    "            activity = power_with_inst_t[~mask]            \n",
    "            epoch_size = 250\n",
    "            epochs = []\n",
    "            for start in range(0, len(activity), epoch_size):\n",
    "                end = start + epoch_size\n",
    "                if end <= len(activity):\n",
    "                    epochs.append(activity[start:end, :-1])\n",
    "                else:\n",
    "                    epochs.append(activity[start:,:-1])\n",
    "                epochs_np=np.array(epochs)\n",
    "            # print('epochs_np', epochs_np.shape)\n",
    "            \n",
    "            activity_mean_epochs = np.mean(epochs_np, axis=0)\n",
    "            # print('activity_mean_epochs.shape:', activity_mean_epochs.shape) #(250, 1)\n",
    "            normalized=activity_mean_epochs/mean_base \n",
    "            \n",
    "            #baseline normalization\n",
    "            nb_e=[]\n",
    "            for i in range (epochs_np.shape[0]):\n",
    "                nb_b_e=[]\n",
    "                for j in range (epochs_np.shape[1]):\n",
    "                    vector1 = epochs_np[i, j,:]\n",
    "                    vector2 =activity_mean_epochs[j]\n",
    "                    result_vector = vector1 #(4*vector1+vector2)/5\n",
    "                    # print(normalized[j], epochs_np[i, j,:]/mean_base)\n",
    "                    nbej=10*np.log10(float(result_vector/mean_base))\n",
    "                    # nbej=10*np.log10(float(1.2*normalized[j]+.5*epochs_np[i, j,:]/mean_base))\n",
    "                    nb_b_e.append(nbej)\n",
    "                nb_e.append(nb_b_e)\n",
    "            nb_e_np=np.array(nb_e)\n",
    "            baseline_normalized=nb_e_np\n",
    "            # print(baseline_normalized.shape)\n",
    "            power_blocks_base_corrected.append(baseline_normalized)\n",
    "        power_matrices_T[channel_name].append(power_blocks_base_corrected)    \n",
    "        ###############################################################################################################################################################\n",
    "np.array(power_matrices_T['C3']).shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 8, 7)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##from here\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "for channel_idx, channel_name in enumerate(selected_columns):\n",
    "    # print(channel_name)\n",
    "    wavelet_coefficient_np=np.array(power_matrices_T[channel_name])\n",
    "    # print(wavelet_coefficient_np.shape)\n",
    "    reshaped_np = wavelet_coefficient_np.transpose(1, 2, 3, 0).reshape(int(wavelet_coefficient_np.shape[1] * 40), 250, 40)\n",
    "    # Checking the new shape\n",
    "    # print(reshaped_np.shape) #(960, 250, 40)\n",
    "    \n",
    "    \n",
    "# Initialize the final numpy array to store the features for each input and each channel\n",
    "num_inputs = reshaped_np.shape[0]\n",
    "num_channels = 8  # As mentioned, assuming there are 8 channels\n",
    "num_features = 7  # Total number of features\n",
    "\n",
    "# The final shape will be (number of inputs, number of channels, number of features)\n",
    "wavelet_feature_array = np.zeros((num_inputs, num_channels, num_features))\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(data):\n",
    "    prob_dist = data / np.sum(data)\n",
    "    return -np.sum(prob_dist * np.log2(prob_dist + np.finfo(float).eps))\n",
    "\n",
    "# Loop over each input and each channel\n",
    "for i in range(num_inputs):\n",
    "    for j in range(num_channels):\n",
    "        # Extracting data for the current input and channel\n",
    "        input_data = reshaped_np[i, :, j]\n",
    "\n",
    "        # Calculating features\n",
    "        mean = np.mean(input_data)\n",
    "        variance = np.var(input_data)\n",
    "        peaks, _ = find_peaks(input_data)\n",
    "        peak_magnitudes = input_data[peaks] if peaks.size > 0 else np.array([0])\n",
    "        max_peak_idx = np.argmax(peak_magnitudes) if peaks.size > 0 else 0\n",
    "        # print(max_peak_idx)\n",
    "        peak_frequency = peaks[max_peak_idx] if peaks.size > 0 else 0\n",
    "        peak_magnitude = peak_magnitudes[max_peak_idx]\n",
    "        energy = np.sum(input_data ** 2)\n",
    "        # entropy = calculate_entropy(input_data)\n",
    "        skewness = skew(input_data)\n",
    "        kurtosis_value = kurtosis(input_data)\n",
    "\n",
    "        # Storing the features in the final array\n",
    "        wavelet_feature_array[i, j, :] = [mean, variance, peak_frequency, peak_magnitude,skewness,  energy, kurtosis_value]\n",
    "        # print(wavelet_feature_array[i, j, :])\n",
    "# Final feature array shape\n",
    "wavelet_feature_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 24, 5, 47, 250)\n",
      "hilbert_feature_matrix (960, 8, 30)\n"
     ]
    }
   ],
   "source": [
    "#Envelop Hilbert feature\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.signal import hilbert, find_peaks, welch\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "fs=250\n",
    "frequency_bands = {\n",
    "    'delta': (1, 4), 'theta': (4, 8),'alpha': (8, 14), 'beta': (14, 30), 'gamma': (30, 40)}    #     'theta': (4, 8),'alpha': (8, 14), 'beta': (14, 30), 'gamma': (30, 40)\n",
    "\n",
    "num_items = len(frequency_bands)\n",
    "baseline_epochs=7\n",
    "epoch_length=250\n",
    "\n",
    "#Hilbert feature\n",
    "data_s= data_T #shape: (8, 11750, 9)\n",
    "hilbert_T=[]\n",
    "for channel_idx, channel_name in enumerate(selected_columns):\n",
    "    hil_block=[]\n",
    "    for block_index in range(len(data_T)):\n",
    "        f_band_env=[]\n",
    "        for band, (lowcut, highcut) in frequency_bands.items():\n",
    "            data = data_s[block_index, :, channel_idx]\n",
    "            data_band= butter_bandpass_filter(data, lowcut, highcut, fs, order=5)\n",
    "            envelope = np.abs(hilbert(data_band))\n",
    "            \n",
    "            # Split into epochs and calculate mean of activity epochs\n",
    "            epochs = np.split(envelope,envelope.shape[0] // epoch_length)\n",
    "            # mean_activity_epoch = np.mean(epochs[baseline_epochs:], axis=0)\n",
    "            \n",
    "            f_band_env.append(epochs)       \n",
    "        hil_block.append(f_band_env)   \n",
    "    hilbert_T.append(hil_block)\n",
    "hilbert_T_np=np.array(hilbert_T)\n",
    "print(hilbert_T_np.shape) #(8, 8, 5, 47, 250)\n",
    "\n",
    "# Initialize the list for the feature matrix\n",
    "hilbert_feature_matrices = []\n",
    "\n",
    "# Iterate over blocks and the last 40 epochs\n",
    "for block in range(block_number):\n",
    "    for epoch in range(7, 47):  # Last 40 epochs\n",
    "        # Initialize a 2D array for this input's features: 8 channels x (5 frequency bands * 6 features)\n",
    "        input_features = np.zeros((8, num_items * 6))\n",
    "\n",
    "        # Iterate over each channel and frequency band\n",
    "        for channel in range(8):\n",
    "            for freq_band in range(num_items):\n",
    "                # Extract the envelope for the current channel, block, frequency band, and epoch\n",
    "                envelope = hilbert_T_np[channel, block, freq_band, epoch, :]\n",
    "\n",
    "                # Compute the features\n",
    "                mean_env = np.mean(envelope)\n",
    "                median_env = np.median(envelope)\n",
    "                std_env = np.std(envelope)\n",
    "                skewness_env = skew(envelope)\n",
    "                kurtosis_env = kurtosis(envelope)\n",
    "                energy = np.sum(envelope**2)\n",
    "\n",
    "                # Combine the features\n",
    "                features = np.array([mean_env, median_env, std_env, skewness_env, kurtosis_env, energy])\n",
    "\n",
    "                # Place the features in the corresponding location in the input_features array\n",
    "                input_features[channel, freq_band * 6:(freq_band + 1) *6] = features\n",
    "\n",
    "        # Append this input's features to the feature matrix list\n",
    "        hilbert_feature_matrices.append(input_features)\n",
    "\n",
    "# Convert the list of feature matrices to a 3D NumPy array\n",
    "hilbert_feature_matrix = np.array(hilbert_feature_matrices) # shape (320, 8, 30)\n",
    "print('hilbert_feature_matrix',hilbert_feature_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 40, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "#ERP feature\n",
    "# Band Pass\n",
    "data_bp = np.copy(data_T)\n",
    "for i in range (len(scene_np)):\n",
    "    for column in range(8):\n",
    "        data_bp[i,:, column] = butter_bandpass_filter(data_bp[i,:, column], lowcut=1, highcut=4, fs=250)\n",
    "data = data_bp \n",
    "data.shape\n",
    "\n",
    "epoch_size = 250\n",
    "epochs = []\n",
    "for i in range (len(data)):\n",
    "    block_epoch=[]\n",
    "    # block_label=data[i,:,-1]\n",
    "    for start in range(1750, (data.shape[1]), epoch_size):\n",
    "        end = start + epoch_size\n",
    "        if end <= (data.shape[1]):\n",
    "            block_epoch.append(data[i, start:end, :])\n",
    "        else:\n",
    "            block_epoch.append(data[i, start:,:])\n",
    "        block_epoch_np=np.array(block_epoch)\n",
    "    block_epoch_np_reshape=block_epoch_np.reshape(block_epoch_np.shape[0], 50,5, block_epoch_np.shape[2])\n",
    "    block_epoch_np_downsample=np.mean(block_epoch_np_reshape, axis=2)\n",
    "    # print(block_epoch_np_downsample.shape)\n",
    "    block_erp_mean=np.mean(block_epoch_np_downsample, axis=0)\n",
    "    # print(block_erp_mean)\n",
    "    epoch_erp=[]\n",
    "    for j in range (len(block_epoch_np_downsample)):\n",
    "        # erpj=(2*block_epoch_np_downsample[j,:,:]+block_erp_mean)/3\n",
    "        erpj=(block_epoch_np_downsample[j,:,:])\n",
    "        epoch_erp.append(erpj)\n",
    "        epoch_erp_np=np.array(epoch_erp)\n",
    "        # print(epoch_erp_np.shape, block_label.shape)\n",
    "    # block_ERP=np.contacenate()\n",
    "    epochs.append(epoch_erp)\n",
    "    ERP_np=np.array(epochs)\n",
    "    \n",
    "ERP_np_eeg=ERP_np[:,:,:,:-1]\n",
    "\n",
    "print(ERP_np_eeg.shape) #: (24, 40, 50, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 40, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ERP_np_eeg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.fft import fft\n",
    "c=(50/1000)\n",
    "W_1= (int(0*c),int(50*c))\n",
    "W_2= (int(80*c),int(210*c))\n",
    "W_3= (int(240*c),int(350*c)) \n",
    "W_4= (int(400*c),int(500*c)) \n",
    "W_5= (int(520*c),int(630*c)) \n",
    "W_6= (int(650*c),int(900*c))\n",
    "W_7= (int(0*c),int(1000*c)) \n",
    "\n",
    "def extract_ERP_features(epoch):\n",
    "    def extract_window_features(window):\n",
    "        amplitude_max = np.max(window)\n",
    "        amplitude_min = np.min(window)\n",
    "        mean_amplitude = np.mean(window)\n",
    "        variance = np.var(window)\n",
    "        std_deviation = np.std(window)\n",
    "        skewness = skew(window)\n",
    "        kurt = kurtosis(window)\n",
    "        peak_to_peak_amplitude = amplitude_max - amplitude_min\n",
    "        zero_crossings = np.where(np.diff(np.sign(window)))[0].size\n",
    "        \n",
    "        # Find peaks\n",
    "        peaks, _ = find_peaks(window)\n",
    "        # print(peaks)\n",
    "        number_of_peaks = len(peaks)\n",
    "        \n",
    "        # # Calculate peak latencies\n",
    "        # latency = (peak_index / sampling_rate) * 1000\n",
    "        peak_latencies = [peak / 50 * 1000 for peak in peaks]  # Replace 'sampling_rate' with your actual rate\n",
    "        \n",
    "        # Frequency domain features (e.g., dominant frequency)\n",
    "        freq_data = fft(window)\n",
    "        dominant_frequency = np.argmax(np.abs(freq_data))\n",
    "\n",
    "        return [mean_amplitude, variance, std_deviation, \n",
    "                peak_to_peak_amplitude, zero_crossings, number_of_peaks ]\n",
    "\n",
    "    W1_region = epoch[W_1[0]:W_1[1]]\n",
    "    W2_region = epoch[W_2[0]:W_2[1]]\n",
    "    W3_region = epoch[W_3[0]:W_3[1]]\n",
    "    W4_region = epoch[W_4[0]:W_4[1]]\n",
    "    W5_region = epoch[W_5[0]:W_5[1]]\n",
    "    W6_region = epoch[W_6[0]:W_6[1]]\n",
    "    W7_region = epoch[W_7[0]:W_7[1]]\n",
    "\n",
    "    W1_features = extract_window_features(W1_region)\n",
    "    W2_features = extract_window_features(W2_region)\n",
    "    W3_features = extract_window_features(W3_region)\n",
    "    W4_features = extract_window_features(W4_region)\n",
    "    W5_features = extract_window_features(W5_region)\n",
    "    W6_features = extract_window_features(W6_region)\n",
    "    W7_features = extract_window_features(W7_region)\n",
    "\n",
    "    return W1_features + W2_features + W3_features + W4_features + W5_features + W6_features  + W7_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs, num_trials_per_run, num_samples, num_channels =  ERP_np_eeg.shape\n",
    "ERP_epoch_EEG = ERP_np_eeg.reshape(num_runs * num_trials_per_run, num_samples, num_channels)\n",
    "\n",
    "ERP_TEPM_FEATURE=[]\n",
    "for i in range(len(ERP_epoch_EEG)):\n",
    "    ERP_W=[]\n",
    "    for j in range( num_channels):\n",
    "        ERP_W_CH=extract_ERP_features(ERP_epoch_EEG[i,:,j])\n",
    "        ERP_W.append(ERP_W_CH)\n",
    "    ERP_W_np=np.array(ERP_W)\n",
    "    ERP_TEPM_FEATURE.append(ERP_W_np)\n",
    "\n",
    "ERP_TEPM_FEATURE_np=np.array(ERP_TEPM_FEATURE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 8, 42)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERP_TEPM_FEATURE_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_data.shape (960, 632)\n",
      "(960, 632) (960,)\n",
      "(960, 632) (960,)\n"
     ]
    }
   ],
   "source": [
    "combined_features = np.concatenate([hilbert_feature_matrix, wavelet_feature_array, ERP_TEPM_FEATURE_np], axis=2)  # ERP_TEPM_FEATURE_np ,LDA_ERP, hilbert_feature_matrix, ERP_matrices_np,wavelet_feature_matrix\n",
    "combined_features.shape\n",
    "\n",
    "##########################################################################################################################\n",
    "#Input to the classifier\n",
    "mlp_data=combined_features.reshape(combined_features.shape[0], combined_features.shape[1]*combined_features.shape[2])\n",
    "print('mlp_data.shape', mlp_data.shape)\n",
    "\n",
    "af_mlp=mlp_data\n",
    "Y_mlp=label_final_np_squeeze\n",
    "\n",
    "print(af_mlp.shape, Y_mlp.shape)\n",
    "af_mlp, Y_mlp= shuffle(af_mlp, Y_mlp)\n",
    "print(af_mlp.shape, Y_mlp.shape)\n",
    "\n",
    "#############################################################################################################################\n",
    "X_train= af_mlp\n",
    "y_train=Y_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 17:40:14,640] A new study created in memory with name: no-name-53565eb6-ff31-4c36-8e18-c4dc0cc9d0d7\n",
      "[I 2024-03-10 17:40:18,327] Trial 0 finished with value: 0.5052083333333333 and parameters: {'n_estimators': 4, 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'auto', 'criterion': 'gini'}. Best is trial 0 with value: 0.5052083333333333.\n",
      "[I 2024-03-10 17:40:19,214] Trial 1 finished with value: 0.5333333333333332 and parameters: {'n_estimators': 3, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 1 with value: 0.5333333333333332.\n",
      "[I 2024-03-10 17:40:19,457] Trial 2 finished with value: 0.5583333333333333 and parameters: {'n_estimators': 7, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:19,770] Trial 3 finished with value: 0.5333333333333333 and parameters: {'n_estimators': 9, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:20,018] Trial 4 finished with value: 0.5020833333333333 and parameters: {'n_estimators': 3, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'auto', 'criterion': 'entropy'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:20,243] Trial 5 finished with value: 0.5218749999999999 and parameters: {'n_estimators': 2, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:20,454] Trial 6 finished with value: 0.5166666666666667 and parameters: {'n_estimators': 5, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:20,686] Trial 7 finished with value: 0.534375 and parameters: {'n_estimators': 3, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'auto', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:20,970] Trial 8 finished with value: 0.5083333333333333 and parameters: {'n_estimators': 6, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'auto', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:21,262] Trial 9 finished with value: 0.5270833333333333 and parameters: {'n_estimators': 10, 'max_depth': 18, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:21,562] Trial 10 finished with value: 0.5125 and parameters: {'n_estimators': 8, 'max_depth': 11, 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:21,902] Trial 11 finished with value: 0.5458333333333333 and parameters: {'n_estimators': 7, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:22,213] Trial 12 finished with value: 0.5583333333333333 and parameters: {'n_estimators': 7, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:22,507] Trial 13 finished with value: 0.5583333333333333 and parameters: {'n_estimators': 7, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:22,796] Trial 14 finished with value: 0.5364583333333333 and parameters: {'n_estimators': 6, 'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:23,098] Trial 15 finished with value: 0.5385416666666666 and parameters: {'n_estimators': 8, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:23,396] Trial 16 finished with value: 0.5583333333333333 and parameters: {'n_estimators': 5, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:23,619] Trial 17 finished with value: 0.5572916666666667 and parameters: {'n_estimators': 8, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:24,048] Trial 18 finished with value: 0.55 and parameters: {'n_estimators': 10, 'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:24,288] Trial 19 finished with value: 0.5229166666666667 and parameters: {'n_estimators': 7, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:24,561] Trial 20 finished with value: 0.5364583333333333 and parameters: {'n_estimators': 6, 'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:24,876] Trial 21 finished with value: 0.5479166666666667 and parameters: {'n_estimators': 7, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 2 with value: 0.5583333333333333.\n",
      "[I 2024-03-10 17:40:25,215] Trial 22 finished with value: 0.578125 and parameters: {'n_estimators': 9, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:25,561] Trial 23 finished with value: 0.546875 and parameters: {'n_estimators': 9, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:25,898] Trial 24 finished with value: 0.5333333333333333 and parameters: {'n_estimators': 9, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:26,186] Trial 25 finished with value: 0.55 and parameters: {'n_estimators': 8, 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:26,579] Trial 26 finished with value: 0.5395833333333333 and parameters: {'n_estimators': 9, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:26,886] Trial 27 finished with value: 0.5083333333333333 and parameters: {'n_estimators': 5, 'max_depth': 11, 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:27,275] Trial 28 finished with value: 0.559375 and parameters: {'n_estimators': 10, 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:27,598] Trial 29 finished with value: 0.5604166666666667 and parameters: {'n_estimators': 10, 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:27,883] Trial 30 finished with value: 0.559375 and parameters: {'n_estimators': 10, 'max_depth': 14, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:28,187] Trial 31 finished with value: 0.5604166666666667 and parameters: {'n_estimators': 10, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:28,502] Trial 32 finished with value: 0.5604166666666667 and parameters: {'n_estimators': 10, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:28,801] Trial 33 finished with value: 0.5604166666666667 and parameters: {'n_estimators': 10, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:29,105] Trial 34 finished with value: 0.5572916666666667 and parameters: {'n_estimators': 9, 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:29,443] Trial 35 finished with value: 0.5416666666666667 and parameters: {'n_estimators': 10, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:29,740] Trial 36 finished with value: 0.5395833333333334 and parameters: {'n_estimators': 9, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:30,040] Trial 37 finished with value: 0.546875 and parameters: {'n_estimators': 10, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:30,380] Trial 38 finished with value: 0.54375 and parameters: {'n_estimators': 9, 'max_depth': 16, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:30,696] Trial 39 finished with value: 0.5437500000000001 and parameters: {'n_estimators': 10, 'max_depth': 20, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:31,018] Trial 40 finished with value: 0.5177083333333334 and parameters: {'n_estimators': 9, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'auto', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:31,312] Trial 41 finished with value: 0.5604166666666667 and parameters: {'n_estimators': 10, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:31,618] Trial 42 finished with value: 0.5604166666666667 and parameters: {'n_estimators': 10, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.578125.\n",
      "[I 2024-03-10 17:40:31,930] Trial 43 finished with value: 0.5791666666666667 and parameters: {'n_estimators': 10, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 43 with value: 0.5791666666666667.\n",
      "[I 2024-03-10 17:40:32,249] Trial 44 finished with value: 0.5489583333333333 and parameters: {'n_estimators': 9, 'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 43 with value: 0.5791666666666667.\n",
      "[I 2024-03-10 17:40:32,519] Trial 45 finished with value: 0.5489583333333333 and parameters: {'n_estimators': 8, 'max_depth': 17, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 43 with value: 0.5791666666666667.\n",
      "[I 2024-03-10 17:40:33,090] Trial 46 finished with value: 0.5333333333333333 and parameters: {'n_estimators': 10, 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'auto', 'criterion': 'entropy'}. Best is trial 43 with value: 0.5791666666666667.\n",
      "[I 2024-03-10 17:40:33,397] Trial 47 finished with value: 0.559375 and parameters: {'n_estimators': 9, 'max_depth': 14, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 43 with value: 0.5791666666666667.\n",
      "[I 2024-03-10 17:40:33,637] Trial 48 finished with value: 0.5125 and parameters: {'n_estimators': 2, 'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 43 with value: 0.5791666666666667.\n",
      "[I 2024-03-10 17:40:33,899] Trial 49 finished with value: 0.575 and parameters: {'n_estimators': 8, 'max_depth': 12, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 43 with value: 0.5791666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 10, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}\n",
      "Best model accuracy: 0.5791666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=17, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=15, n_estimators=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=17, max_features=&#x27;log2&#x27;, min_samples_leaf=2,\n",
       "                       min_samples_split=15, n_estimators=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=17, max_features='log2', min_samples_leaf=2,\n",
       "                       min_samples_split=15, n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 2, 10)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2,20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 5)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "\n",
    "    # Create the random forest classifier with suggested values\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        criterion=criterion,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # K-fold cross-validation\n",
    "    accuracies = cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=5)\n",
    "\n",
    "    # Compute the average accuracy\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    return average_accuracy\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "print('Best parameters:', best_params)\n",
    "best_score = study.best_value\n",
    "print(f'Best model accuracy: {best_score}')\n",
    "\n",
    "# Create and fit the model with the best parameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    criterion=best_params['criterion'],\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_accuracy 0.5729166666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Initialize the classifier with the best parameters\n",
    "clf = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Plotting setup\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Perform K-Fold CV\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_proba_fold = clf.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "\n",
    "    # Compute and store the accuracy for this fold\n",
    "    fold_accuracy = accuracy_score(y_val_fold, clf.predict(X_val_fold))\n",
    "    accuracies.append(fold_accuracy)\n",
    "\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print('mean_accuracy', mean_accuracy)\n",
    "# std_auc = np.std(aucs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.joblib']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the model\n",
    "dump(clf, 'random_forest_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-10 17:40:56,152] A new study created in memory with name: no-name-3d12ac3f-e84f-422b-a2c0-e2de190ebcdf\n",
      "[I 2024-03-10 17:40:57,223] Trial 0 finished with value: 0.5 and parameters: {'C': 5.727810423935379, 'gamma': 7.552989824770152}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-03-10 17:40:58,284] Trial 1 finished with value: 0.6010416666666667 and parameters: {'C': 0.849213284496791, 'gamma': 0.00206641746828133}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:40:59,317] Trial 2 finished with value: 0.5 and parameters: {'C': 362.9771216876668, 'gamma': 811.2209160501204}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:00,350] Trial 3 finished with value: 0.5 and parameters: {'C': 162.68353223433823, 'gamma': 146.8458871076755}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:01,366] Trial 4 finished with value: 0.5354166666666667 and parameters: {'C': 1.3282270339674205, 'gamma': 0.4011789076682915}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:02,414] Trial 5 finished with value: 0.53125 and parameters: {'C': 0.27113443440775586, 'gamma': 0.8741760569733639}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:03,466] Trial 6 finished with value: 0.5 and parameters: {'C': 59.26300156865753, 'gamma': 5.578220353089807}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:04,518] Trial 7 finished with value: 0.5 and parameters: {'C': 30.634890647270314, 'gamma': 21.271739272029567}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:05,561] Trial 8 finished with value: 0.5 and parameters: {'C': 94.94633686271806, 'gamma': 521.3499545824085}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:06,606] Trial 9 finished with value: 0.5 and parameters: {'C': 61.82993196738639, 'gamma': 4.553557260349427}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:07,649] Trial 10 finished with value: 0.5552083333333333 and parameters: {'C': 0.012095429989505496, 'gamma': 0.0016273870656240198}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:08,695] Trial 11 finished with value: 0.5552083333333333 and parameters: {'C': 0.00660586696312458, 'gamma': 0.0011940703095958578}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:09,719] Trial 12 finished with value: 0.5552083333333334 and parameters: {'C': 0.0302731846159309, 'gamma': 0.0017849822111839864}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:10,706] Trial 13 finished with value: 0.5052083333333333 and parameters: {'C': 0.09116735806539801, 'gamma': 0.010050955291571009}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:11,714] Trial 14 finished with value: 0.4989583333333333 and parameters: {'C': 0.0023082167599938566, 'gamma': 0.0183917320281047}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:12,714] Trial 15 finished with value: 0.503125 and parameters: {'C': 0.042208680700052695, 'gamma': 0.08239161464476592}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:13,719] Trial 16 finished with value: 0.5104166666666667 and parameters: {'C': 0.617467802859875, 'gamma': 0.007024456947877525}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:14,734] Trial 17 finished with value: 0.5010416666666667 and parameters: {'C': 0.0011880937053866292, 'gamma': 0.0678398997757107}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:15,741] Trial 18 finished with value: 0.55625 and parameters: {'C': 0.07754494596431923, 'gamma': 0.0011621844087964964}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:16,702] Trial 19 finished with value: 0.6 and parameters: {'C': 2.9903153008827426, 'gamma': 0.005388528618292275}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:17,719] Trial 20 finished with value: 0.4885416666666667 and parameters: {'C': 4.729470302771042, 'gamma': 0.04673268465127862}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:18,745] Trial 21 finished with value: 0.546875 and parameters: {'C': 0.28905299104988286, 'gamma': 0.004398909070733476}. Best is trial 1 with value: 0.6010416666666667.\n",
      "[I 2024-03-10 17:41:19,785] Trial 22 finished with value: 0.6072916666666667 and parameters: {'C': 1.973027754061388, 'gamma': 0.001099779083766495}. Best is trial 22 with value: 0.6072916666666667.\n",
      "[I 2024-03-10 17:41:20,800] Trial 23 finished with value: 0.609375 and parameters: {'C': 2.2972581708077136, 'gamma': 0.004056497497095341}. Best is trial 23 with value: 0.609375.\n",
      "[I 2024-03-10 17:41:21,796] Trial 24 finished with value: 0.4989583333333334 and parameters: {'C': 14.908123071640611, 'gamma': 0.021016696166805706}. Best is trial 23 with value: 0.609375.\n",
      "[I 2024-03-10 17:41:22,799] Trial 25 finished with value: 0.6187499999999999 and parameters: {'C': 1.5061764413031307, 'gamma': 0.0034534736524812417}. Best is trial 25 with value: 0.6187499999999999.\n",
      "[I 2024-03-10 17:41:23,818] Trial 26 finished with value: 0.5979166666666667 and parameters: {'C': 10.58376596199225, 'gamma': 0.0048865718375453275}. Best is trial 25 with value: 0.6187499999999999.\n",
      "[I 2024-03-10 17:41:24,754] Trial 27 finished with value: 0.4989583333333333 and parameters: {'C': 2.2465102311524614, 'gamma': 0.023908073241339745}. Best is trial 25 with value: 0.6187499999999999.\n",
      "[I 2024-03-10 17:41:25,683] Trial 28 finished with value: 0.4989583333333333 and parameters: {'C': 15.93829382620453, 'gamma': 0.16060245172994292}. Best is trial 25 with value: 0.6187499999999999.\n",
      "[I 2024-03-10 17:41:26,636] Trial 29 finished with value: 0.6177083333333333 and parameters: {'C': 6.156201990917061, 'gamma': 0.0030971224292309788}. Best is trial 25 with value: 0.6187499999999999.\n",
      "[I 2024-03-10 17:41:27,647] Trial 30 finished with value: 0.5197916666666667 and parameters: {'C': 5.561478409804392, 'gamma': 0.012748186361887749}. Best is trial 25 with value: 0.6187499999999999.\n",
      "[I 2024-03-10 17:41:28,659] Trial 31 finished with value: 0.6229166666666666 and parameters: {'C': 2.412348406580939, 'gamma': 0.0025326486323775056}. Best is trial 31 with value: 0.6229166666666666.\n",
      "[I 2024-03-10 17:41:29,663] Trial 32 finished with value: 0.6270833333333333 and parameters: {'C': 6.138030646170391, 'gamma': 0.0034765276210150177}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:30,647] Trial 33 finished with value: 0.6062500000000001 and parameters: {'C': 7.664121770793282, 'gamma': 0.004519917372784239}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:31,638] Trial 34 finished with value: 0.5968749999999999 and parameters: {'C': 0.8698596507705534, 'gamma': 0.0025867874677630025}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:32,682] Trial 35 finished with value: 0.5333333333333334 and parameters: {'C': 4.903499952101143, 'gamma': 0.010279931854138509}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:33,673] Trial 36 finished with value: 0.6239583333333334 and parameters: {'C': 24.28865805741529, 'gamma': 0.002642201892298864}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:34,626] Trial 37 finished with value: 0.496875 and parameters: {'C': 19.657036999605033, 'gamma': 0.03310416489500659}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:35,576] Trial 38 finished with value: 0.5260416666666666 and parameters: {'C': 267.4047746767496, 'gamma': 0.01133748934808263}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:36,586] Trial 39 finished with value: 0.6239583333333334 and parameters: {'C': 562.0778287974505, 'gamma': 0.002646775936382392}. Best is trial 32 with value: 0.6270833333333333.\n",
      "[I 2024-03-10 17:41:37,590] Trial 40 finished with value: 0.63125 and parameters: {'C': 961.0448126742856, 'gamma': 0.0020031524166434786}. Best is trial 40 with value: 0.63125.\n",
      "[I 2024-03-10 17:41:38,616] Trial 41 finished with value: 0.6270833333333333 and parameters: {'C': 998.4714708354059, 'gamma': 0.0022913715210297566}. Best is trial 40 with value: 0.63125.\n",
      "[I 2024-03-10 17:41:39,653] Trial 42 finished with value: 0.6312500000000001 and parameters: {'C': 830.0900872246474, 'gamma': 0.0010850547980249398}. Best is trial 42 with value: 0.6312500000000001.\n",
      "[I 2024-03-10 17:41:40,666] Trial 43 finished with value: 0.6364583333333333 and parameters: {'C': 797.4775002874688, 'gamma': 0.001222745888663791}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:41,691] Trial 44 finished with value: 0.6333333333333334 and parameters: {'C': 954.1916865064901, 'gamma': 0.0013486889052309015}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:42,673] Trial 45 finished with value: 0.6312500000000001 and parameters: {'C': 175.03344640483022, 'gamma': 0.0010451415260502616}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:43,635] Trial 46 finished with value: 0.6322916666666667 and parameters: {'C': 201.73646090808782, 'gamma': 0.0010321938558538618}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:44,596] Trial 47 finished with value: 0.6312500000000001 and parameters: {'C': 177.08394384862686, 'gamma': 0.0010759676531156652}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:45,569] Trial 48 finished with value: 0.5666666666666667 and parameters: {'C': 389.9210839285675, 'gamma': 0.007644108502079871}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:46,591] Trial 49 finished with value: 0.6333333333333334 and parameters: {'C': 114.44436981346539, 'gamma': 0.0010270952852087477}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:47,618] Trial 50 finished with value: 0.6302083333333334 and parameters: {'C': 94.55574670253114, 'gamma': 0.0016068336852674621}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:48,638] Trial 51 finished with value: 0.6322916666666667 and parameters: {'C': 208.61925208953156, 'gamma': 0.0014375876453225763}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:49,668] Trial 52 finished with value: 0.6322916666666666 and parameters: {'C': 530.5475594546313, 'gamma': 0.0016763212182991597}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:50,716] Trial 53 finished with value: 0.58125 and parameters: {'C': 396.65688357598617, 'gamma': 0.006761008445601556}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:51,757] Trial 54 finished with value: 0.6291666666666667 and parameters: {'C': 255.62543522577542, 'gamma': 0.0021117964037017252}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:52,772] Trial 55 finished with value: 0.6312500000000001 and parameters: {'C': 551.3999208823013, 'gamma': 0.0016346009912579736}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:53,797] Trial 56 finished with value: 0.5479166666666666 and parameters: {'C': 45.38051343994534, 'gamma': 0.008225433013716183}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:54,820] Trial 57 finished with value: 0.6291666666666667 and parameters: {'C': 105.88503165270254, 'gamma': 0.0015691800996856357}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:55,821] Trial 58 finished with value: 0.5979166666666667 and parameters: {'C': 249.26395315305206, 'gamma': 0.005736789315295663}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:56,821] Trial 59 finished with value: 0.5072916666666666 and parameters: {'C': 592.4570862164073, 'gamma': 0.015512836058736539}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:57,837] Trial 60 finished with value: 0.63125 and parameters: {'C': 116.79497780742625, 'gamma': 0.0017116762659926963}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:58,835] Trial 61 finished with value: 0.6322916666666667 and parameters: {'C': 714.0496580296218, 'gamma': 0.0011239011114736169}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:41:59,855] Trial 62 finished with value: 0.6333333333333334 and parameters: {'C': 336.454325211497, 'gamma': 0.001028142096357154}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:00,833] Trial 63 finished with value: 0.6322916666666667 and parameters: {'C': 304.7920186108431, 'gamma': 0.0010616790353781083}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:01,788] Trial 64 finished with value: 0.61875 and parameters: {'C': 44.575852945754505, 'gamma': 0.0038179242950973865}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:02,805] Trial 65 finished with value: 0.5947916666666666 and parameters: {'C': 168.48089114125486, 'gamma': 0.005795250063024595}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:03,855] Trial 66 finished with value: 0.6270833333333333 and parameters: {'C': 67.55595672119365, 'gamma': 0.0034824783727517732}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:04,841] Trial 67 finished with value: 0.6322916666666667 and parameters: {'C': 370.3383502806738, 'gamma': 0.0010612367540167114}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:05,859] Trial 68 finished with value: 0.63125 and parameters: {'C': 716.7505105937781, 'gamma': 0.0016952603751511847}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:06,860] Trial 69 finished with value: 0.6114583333333334 and parameters: {'C': 443.43558318549105, 'gamma': 0.003987935885263505}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:07,899] Trial 70 finished with value: 0.6197916666666667 and parameters: {'C': 217.02212722665072, 'gamma': 0.002750579750799074}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:08,928] Trial 71 finished with value: 0.6333333333333334 and parameters: {'C': 358.6836109604742, 'gamma': 0.0010162163429341463}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:09,931] Trial 72 finished with value: 0.6291666666666667 and parameters: {'C': 717.660959377832, 'gamma': 0.0015558764928484702}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:10,951] Trial 73 finished with value: 0.6333333333333334 and parameters: {'C': 142.8627615782184, 'gamma': 0.0010274083498883957}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:11,970] Trial 74 finished with value: 0.6270833333333334 and parameters: {'C': 108.80970161730754, 'gamma': 0.002389129361733884}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:12,973] Trial 75 finished with value: 0.596875 and parameters: {'C': 301.3808472374257, 'gamma': 0.004915561897619801}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:13,984] Trial 76 finished with value: 0.628125 and parameters: {'C': 173.76996451765785, 'gamma': 0.001470537524500492}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:14,999] Trial 77 finished with value: 0.628125 and parameters: {'C': 396.5457047386189, 'gamma': 0.0021888884311878176}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:15,995] Trial 78 finished with value: 0.5364583333333334 and parameters: {'C': 74.528011185547, 'gamma': 0.008921253277688257}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:17,038] Trial 79 finished with value: 0.6260416666666667 and parameters: {'C': 136.61999745682655, 'gamma': 0.0034583415634068743}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:18,042] Trial 80 finished with value: 0.6333333333333334 and parameters: {'C': 231.8230897006397, 'gamma': 0.0013570107230686942}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:19,000] Trial 81 finished with value: 0.628125 and parameters: {'C': 222.44469495336136, 'gamma': 0.0014937051716770128}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:20,118] Trial 82 finished with value: 0.628125 and parameters: {'C': 141.57162279620516, 'gamma': 0.002305343766762378}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:21,089] Trial 83 finished with value: 0.6322916666666667 and parameters: {'C': 481.28685770973493, 'gamma': 0.0010378055615279695}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:22,096] Trial 84 finished with value: 0.6177083333333333 and parameters: {'C': 313.9317178469751, 'gamma': 0.003049459429288614}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:23,117] Trial 85 finished with value: 0.634375 and parameters: {'C': 957.3247982910914, 'gamma': 0.0010061675418816538}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:24,133] Trial 86 finished with value: 0.6031250000000001 and parameters: {'C': 965.2801334629728, 'gamma': 0.004764114136189229}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:25,159] Trial 87 finished with value: 0.6291666666666667 and parameters: {'C': 481.69069032311603, 'gamma': 0.0021532949602172695}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:26,167] Trial 88 finished with value: 0.6333333333333334 and parameters: {'C': 669.2714509758647, 'gamma': 0.0010154077068980174}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:27,220] Trial 89 finished with value: 0.628125 and parameters: {'C': 651.5353902103038, 'gamma': 0.0014708723686832634}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:28,239] Trial 90 finished with value: 0.6197916666666667 and parameters: {'C': 974.592176222067, 'gamma': 0.0031756744728685163}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:29,261] Trial 91 finished with value: 0.6322916666666667 and parameters: {'C': 326.86481740164857, 'gamma': 0.001058452031439745}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:30,425] Trial 92 finished with value: 0.63125 and parameters: {'C': 562.9908745941733, 'gamma': 0.002012085496330085}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:31,537] Trial 93 finished with value: 0.6333333333333334 and parameters: {'C': 726.5184194333983, 'gamma': 0.0013400600908639341}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:32,557] Trial 94 finished with value: 0.6322916666666667 and parameters: {'C': 748.661009186904, 'gamma': 0.0012918409049993227}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:33,608] Trial 95 finished with value: 0.63125 and parameters: {'C': 426.7403603275822, 'gamma': 0.0018537644018777766}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:34,619] Trial 96 finished with value: 0.621875 and parameters: {'C': 268.6731212828402, 'gamma': 0.0027041254858488836}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:35,653] Trial 97 finished with value: 0.6333333333333334 and parameters: {'C': 773.0283152534732, 'gamma': 0.0013332821524454574}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:36,670] Trial 98 finished with value: 0.5864583333333333 and parameters: {'C': 564.0958231166794, 'gamma': 0.006181082832007364}. Best is trial 43 with value: 0.6364583333333333.\n",
      "[I 2024-03-10 17:42:37,679] Trial 99 finished with value: 0.6072916666666667 and parameters: {'C': 138.0596271304603, 'gamma': 0.004321369189405153}. Best is trial 43 with value: 0.6364583333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 797.4775002874688, 'gamma': 0.001222745888663791}\n",
      "Best cross-validation score: 0.6364583333333333\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def objective(trial):\n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "    gamma = trial.suggest_float('gamma', 1e-3, 1e3, log=True)\n",
    "    \n",
    "    # Define a pipeline to ensure scaling is done within each CV fold\n",
    "    svc = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(C=C, gamma=gamma, kernel='rbf', class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Use stratified K-Fold to maintain class distribution\n",
    "    stratified_cv = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    # Obtain the cross-validation score\n",
    "    score_svm = cross_val_score(svc, X_train, y_train, n_jobs=-1, cv=stratified_cv).mean()\n",
    "    return score_svm\n",
    "\n",
    "study_svm = optuna.create_study(direction='maximize')\n",
    "study_svm.optimize(objective, n_trials=100)\n",
    "\n",
    "# After the study, print the best parameters and their corresponding score\n",
    "best_params_svm = study_svm.best_params\n",
    "best_score_svm= study_svm.best_value\n",
    "print(f'Best parameters found: {best_params_svm}')\n",
    "print(f'Best cross-validation score: {best_score_svm}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6208333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['final_svc_model.joblib']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Assuming X_train, y_train are defined and study.best_params has been set\n",
    "best_params_svm = study_svm.best_params\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "accuracies_svm = []  # List to store accuracy for each fold\n",
    "\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(stratified_cv.split(X_train, y_train)):\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    # Create and fit the model on the training fold\n",
    "    model_svm = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(**best_params_svm, kernel='rbf', class_weight='balanced', probability=True, random_state=42))\n",
    "    ])\n",
    "    model_svm.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probs_svm = model_svm.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "    # Compute ROC curve and area under the curve\n",
    " \n",
    "\n",
    "    # Calculate and store the accuracy for this fold\n",
    "    fold_accuracy_svm = accuracy_score(y_test_fold, model_svm.predict(X_test_fold))\n",
    "    accuracies_svm.append(fold_accuracy_svm)\n",
    "\n",
    "\n",
    "\n",
    "mean_accuracy_svm = np.mean(accuracies_svm)  # Mean accuracy across all folds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print out the mean accuracy\n",
    "print(f\"Mean accuracy: {mean_accuracy_svm}\")\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with the best parameters on the scaled data\n",
    "best_model_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(**best_params_svm, kernel='rbf', class_weight='balanced', random_state=42))\n",
    "])\n",
    "best_model_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "joblib.dump(best_model_svm, 'final_svc_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
