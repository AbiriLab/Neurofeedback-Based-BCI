{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vMaBF4q9pl9k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import hilbert\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.signal import butter, filtfilt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.layers import Dense,  BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_name = input(\"Please enter the subject name: \")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bvs0pSXWpl9m",
        "outputId": "554c9aa5-47a2-4247-da93-56e4cafad9d0"
      },
      "outputs": [],
      "source": [
        "# Define the column names\n",
        "column_names = ['FZ', 'FC1', 'FC2', 'C3', 'CZ', 'C4', 'CPZ', 'PZ', 'AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ',\n",
        "                'Battery', 'Sample', 'Unknown', 'Instruction', 'Female/Male', 'Outdoor/Indoor', 'Human Behavior']\n",
        "df = []\n",
        "if os.path.exists(folder_name) and os.path.isdir(folder_name):\n",
        "    for file_name in os.listdir(folder_name):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_name, file_name)\n",
        "            df_temp = pd.read_csv(file_path, header=None)\n",
        "            df.append(df_temp)     \n",
        "    combined_data_array_3d = np.array(df)\n",
        "    combined_data_array_2d= combined_data_array_3d.reshape(40 * 10000, 21)\n",
        "    \n",
        "Combined_raw_eeg = pd.DataFrame(combined_data_array_2d) \n",
        "Combined_raw_eeg.columns = column_names\n",
        "\n",
        "#Excluding the useless columns\n",
        "columns_to_remove = ['AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ', 'Battery', 'Sample', 'Unknown','Instruction','Female/Male', 'Outdoor/Indoor', 'Human Behavior']\n",
        "Combined_raw_eeg = Combined_raw_eeg.drop(columns=columns_to_remove, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "# Band pass filter\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "Combined_raw_eeg_bp = np.copy(Combined_raw_eeg)\n",
        "num_columns = Combined_raw_eeg_bp.shape[1]\n",
        "print(num_columns)\n",
        "for column in range(num_columns):\n",
        "    Combined_raw_eeg_bp[:, column] = butter_bandpass_filter(Combined_raw_eeg_bp[:, column], lowcut=.4, highcut=40, fs=250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-proccessing\n",
        "# Denoising \n",
        "def denoise_data(df, col_names, n_clusters):\n",
        "    df_denoised = df.copy()\n",
        "    for col_name, k in zip(col_names, n_clusters):\n",
        "        df_denoised[col_name] = pd.to_numeric(df_denoised[col_name], errors='coerce') # Convert column to numeric format\n",
        "        X = df_denoised.select_dtypes(include=['float64', 'int64']) # Select only numeric columns\n",
        "        clf = KNeighborsRegressor(n_neighbors=k, weights='uniform') # Fit KNeighborsRegressor\n",
        "        clf.fit(X.index.values[:, np.newaxis], X[col_name])\n",
        "        y_pred = clf.predict(X.index.values[:, np.newaxis]) # Predict values \n",
        "        df_denoised[col_name] = y_pred\n",
        "    return df_denoised\n",
        "\n",
        "# Z_scoring\n",
        "def z_score(df, col_names):\n",
        "    df_standard = df.copy()\n",
        "    for col in col_names:\n",
        "        df_standard[col] = (df[col] - df[col].mean()) / df[col].std()\n",
        "    return df_standard\n",
        "\n",
        "# Detrending\n",
        "def detrend(df, col_names):\n",
        "    df_detrended = df.copy()\n",
        "    for col in col_names:\n",
        "        y = df_detrended[col]\n",
        "        x = np.arange(len(y))\n",
        "        p = np.polyfit(x, y, 1)\n",
        "        trend = np.polyval(p, x)\n",
        "        detrended = y - trend\n",
        "        df_detrended[col] = detrended\n",
        "    return df_detrended\n",
        "\n",
        "def preprocess(df, col_names, n_clusters):\n",
        "    df_new = df.copy()\n",
        "    df_new = denoise_data(df, col_names, n_clusters)\n",
        "    df_new = z_score(df_new, col_names)\n",
        "    df_new = detrend(df_new, col_names)\n",
        "    return df_new\n",
        "\n",
        "Combined_raw_eeg_bp=pd.DataFrame(Combined_raw_eeg_bp)\n",
        "eeg_df_denoised = preprocess(Combined_raw_eeg_bp, col_names=list(Combined_raw_eeg_bp.columns), n_clusters=[50]*len(Combined_raw_eeg_bp.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lableing\n",
        "column_indices = {'Instruction': 17, 'Female/Male': 18, 'Outdoor/Indoor': 19}\n",
        "selected_columns = [column_indices['Instruction'], column_indices['Female/Male'], column_indices['Outdoor/Indoor']]\n",
        "data_im_ins = combined_data_array_2d[:, selected_columns]\n",
        "denoised_im_ins = np.concatenate((eeg_df_denoised, data_im_ins), axis=1)\n",
        "\n",
        "# Check the third last column (column 9) and keep rows if column 9 is equal to 1\n",
        "filtered_denoised_im_ins = denoised_im_ins[(denoised_im_ins[:, -3] == denoised_im_ins[:, -2]) | (denoised_im_ins[:, -3] == denoised_im_ins[:, -1])]\n",
        "filtered_denoised_im_ins_df = pd.DataFrame(filtered_denoised_im_ins)\n",
        "\n",
        "# Create a new column 'event'\n",
        "filtered_denoised_im_ins_df['event'] = ''\n",
        "for index, row in filtered_denoised_im_ins_df.iterrows():\n",
        "    if row.iloc[-4] == 'F' or row.iloc[-4] == 'M':\n",
        "        filtered_denoised_im_ins_df.at[index, 'event'] = '0'\n",
        "    elif row.iloc[-4] == 'I' or row.iloc[-4] == 'O':\n",
        "        filtered_denoised_im_ins_df.at[index, 'event'] = '1'\n",
        "        \n",
        "selected_data = filtered_denoised_im_ins_df.iloc[:, :8]  \n",
        "lable=filtered_denoised_im_ins_df.iloc[:, -1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(360000, 8)\n"
          ]
        }
      ],
      "source": [
        "print(selected_data.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Windowing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "win_size = 250\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(0, len(selected_data), win_size):\n",
        "    window_data = selected_data.iloc[i:i+win_size]\n",
        "    window_label = lable.iloc[i:i+win_size]\n",
        "    X.append(window_data)\n",
        "    y.append(window_label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X, y = shuffle(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1440, 250, 8) (1440, 250, 1)\n",
            "(1440, 250)\n",
            "1440\n",
            "250\n",
            "(250,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape, y.shape)\n",
        "print(X[:,:, 7].shape)\n",
        "print(X.shape[0])\n",
        "print(X.shape[1])\n",
        "print(X[5,:, 2].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1440, 2000)\n",
            "(1440, 250, 8)\n",
            "1440\n"
          ]
        }
      ],
      "source": [
        "array_3d = X.reshape(1440, 250*8)\n",
        "print(array_3d.shape)\n",
        "print(X.shape)\n",
        "print(array_3d.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.signal import welch\n",
        "\n",
        "# Define the frequency bands\n",
        "freq_bands = {'Delta': (0, 4),\n",
        "              'Theta': (4, 8),\n",
        "              'Alpha': (8, 13),\n",
        "              'Beta': (13, 30),\n",
        "              'Gamma': (30, 100)}\n",
        "\n",
        "def get_eeg_features(eeg_data, fs):\n",
        "    # Calculate the frequency spectrum using Welch's method\n",
        "    freqs, psd = welch(eeg_data, fs, nperseg=fs, noverlap=fs//2)\n",
        "\n",
        "    # Initialize a dictionary to hold the features\n",
        "    features = {}\n",
        "\n",
        "    # For each frequency band, integrate the PSD within that band\n",
        "    for band, (low, high) in freq_bands.items():\n",
        "        idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "        power = np.trapz(psd[idx_band], freqs[idx_band])\n",
        "        # Ensure the power value is real using abs to get magnitude of complex number\n",
        "        power = abs(power)\n",
        "        features[band] = power\n",
        "\n",
        "    return features\n",
        "\n",
        "# # Your EEG data is X\n",
        "# X = np.random.rand(1440, 250, 8)  # Replace this with your real EEG data\n",
        "\n",
        "# Initialize an array to store the features\n",
        "frequency_domain_features = np.empty((1440, 8, len(freq_bands)))\n",
        "\n",
        "# Iterate over the data\n",
        "for i in range(1440):  # For each image\n",
        "    for k in range(8):  # For each channel\n",
        "        # Extract the features\n",
        "        feature_values = get_eeg_features(X[i, :, k], fs=250)\n",
        "        frequency_domain_features[i, k] = list(feature_values.values())\n",
        "# print(features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1440, 250, 8)\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index 5 is out of bounds for axis 2 with size 5",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[106], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m         erp_features[i, k] \u001b[39m=\u001b[39m extract_erp_features(X[i, :, k])\n\u001b[0;32m     52\u001b[0m         hilbert_features[i, k] \u001b[39m=\u001b[39m extract_hilbert_features(X[i, :, k])\n\u001b[1;32m---> 53\u001b[0m         hilbert_features_freq[i, k] \u001b[39m=\u001b[39m extract_hilbert_features(frequency_domain_features[i, :, k])\n\u001b[0;32m     54\u001b[0m         xf[i, k]\u001b[39m=\u001b[39mX[i, :, k]\n\u001b[0;32m     55\u001b[0m \u001b[39m# Now you have time domain features and ERP features for each trial and each channel\u001b[39;00m\n",
            "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 2 with size 5"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.signal import welch\n",
        "\n",
        "\n",
        "# Convert the data to a numerical type (float)\n",
        "X = X.astype(np.float64)\n",
        "print(X.shape)\n",
        "\n",
        "# Define the size of the features\n",
        "n_trials, n_samples, n_channels = X.shape\n",
        "n_features = 5  # The number of time domain features we're going to compute\n",
        "\n",
        "# Time domain features\n",
        "def extract_time_domain_features(X):\n",
        "    mean = np.mean(X)\n",
        "    median = np.median(X)\n",
        "    std_dev = np.std(X)    # Standard deviation\n",
        "    skewness = skew(X)     # Skewness\n",
        "    kurt = kurtosis(X)     # Kurtosis\n",
        "    return [mean, median, std_dev, skewness, kurt]\n",
        "# ERP features (assuming the EEG data is already aligned to the event)\n",
        "\n",
        "def extract_erp_features(X):\n",
        "    mean_amp = np.mean(X) # Mean amplitude\n",
        "    peak_latency = np.argmax(X) # Peak latency (time to peak)\n",
        "    peak_amp = np.max(X) # Peak amplitude\n",
        "    return [mean_amp, peak_latency, peak_amp]\n",
        "\n",
        "def extract_hilbert_features(X):\n",
        "    # Compute the analytic signal, from which you can get the envelope and instantaneous phase\n",
        "    analytic_signal = hilbert(X)\n",
        "    # Envelope is the absolute value of the analytic signal\n",
        "    envelope = np.abs(analytic_signal)\n",
        "    # Mean and standard deviation of the envelope can be interesting features\n",
        "    mean_envelope = np.mean(envelope)\n",
        "    std_dev_envelope = np.std(envelope)\n",
        "    return [mean_envelope, std_dev_envelope]\n",
        "    # return envelope \n",
        "\n",
        "# Initialize arrays to hold the features\n",
        "time_domain_features = np.zeros((n_trials, n_channels, 5)) # 5 time domain features\n",
        "erp_features = np.zeros((n_trials, n_channels, 3)) # 3 ERP features\n",
        "hilbert_features = np.zeros((n_trials, n_channels, 2))  # 2 Hilbert features\n",
        "hilbert_features_freq=np.zeros((n_trials, n_channels, 2))\n",
        "xf=np.zeros((n_trials, n_channels, 250))\n",
        "# Loop over trials and channels and extract features \n",
        "for i in range(n_trials):\n",
        "    for k in range(n_channels):\n",
        "        time_domain_features[i, k] = extract_time_domain_features(X[i, :, k])\n",
        "        erp_features[i, k] = extract_erp_features(X[i, :, k])\n",
        "        hilbert_features[i, k] = extract_hilbert_features(X[i, :, k])\n",
        "        hilbert_features_freq[i, k] = extract_hilbert_features(frequency_domain_features[i, :, k])\n",
        "        xf[i, k]=X[i, :, k]\n",
        "# Now you have time domain features and ERP features for each trial and each channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1440, 8, 250)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1440, 8, 265)\n"
          ]
        }
      ],
      "source": [
        "all_features = np.concatenate([time_domain_features, erp_features, hilbert_features_freq, hilbert_features, xf], axis=-1)\n",
        "print(all_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1440, 8, 13)\n",
            "(1440, 250, 8)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from scipy.signal import hilbert\n",
        "import scipy.signal\n",
        "\n",
        "\n",
        "analytic_signal_features = hilbert(all_features)\n",
        "analytic_signal_features2=hilbert(X)\n",
        "\n",
        "# # If you want to get the absolute envelope of this analytic signal, use:\n",
        "envelope_features = np.abs(analytic_signal_features)\n",
        "envelope_features2 = np.abs(analytic_signal_features2)\n",
        "\n",
        "print(envelope_features.shape)\n",
        "print(envelope_features2.shape)\n",
        "\n",
        "# print(envelope_features.shape)\n",
        "# envelope=np.hstack((envelope_features, array_3d))\n",
        "\n",
        "# feature=envelope\n",
        "# # feature=envelope_features\n",
        "# print(len(feature))\n",
        "# feature_array=np.array(envelope_features)\n",
        "# X_n=feature_array\n",
        "# print(X_n.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "XF=all_features.reshape(1440, 8*265)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1440, 2120) (1440,)\n"
          ]
        }
      ],
      "source": [
        "y_n=np.squeeze(y[:,0])\n",
        "print(XF.shape, y_n.shape)\n",
        "\n",
        "# Balance the dataset\n",
        "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(XF, y_n)\n",
        "X_resampled= X_resampled.astype(np.float32)\n",
        "y_resampled = y_resampled.astype(np.int32)\n",
        "\n",
        "# Split X and y into training and testing sets\n",
        "X_touched, X_untouch, y_touch, y_untouch = train_test_split(X_resampled, y_resampled, test_size=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_touched, y_touch, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert y_train and y_test to categorical format for Keras\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "y_untouch=tf.keras.utils.to_categorical(y_untouch, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1166,) (130,)\n"
          ]
        }
      ],
      "source": [
        "# Convert one-hot-encoded labels to integer-encoded labels\n",
        "y_train = np.argmax(y_train, axis=-1)\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_untouch = np.argmax(y_untouch, axis=-1)\n",
        "print(y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (1166, 2120) y_train: (1166,) X_test: (130, 2120) y_test: (130,) X_untouch: (144, 2120) y_untouch: (144,)\n"
          ]
        }
      ],
      "source": [
        "print('X_train:', X_train.shape, 'y_train:', y_train.shape, 'X_test:', X_test.shape, 'y_test:',\n",
        "      y_test.shape, 'X_untouch:', X_untouch.shape, 'y_untouch:', y_untouch.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy:  0.6384615384615384\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.61      0.63        66\n",
            "           1       0.62      0.67      0.65        64\n",
            "\n",
            "    accuracy                           0.64       130\n",
            "   macro avg       0.64      0.64      0.64       130\n",
            "weighted avg       0.64      0.64      0.64       130\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from joblib import dump\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "# Create a linear SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "# Save the model to disk\n",
        "filename = 'C:/Users/tnlab/OneDrive/Documents/GitHub/Neurofeedback-Based-BCI/SVM for Unicorn Data/my_svm_model.joblib'\n",
        "dump(clf, filename)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print('Model accuracy: ', accuracy_score(y_test, y_pred))\n",
        "report_svm_matrix = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report_svm_matrix)\n",
        "report_svm = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "report_df_svm = pd.DataFrame(report_svm).transpose()\n",
        "report_df_svm.to_excel(f\"svm_classification_report_{folder_name}.xlsx\", index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hilbert feature extraction and PCA data Reduction\n",
        "import numpy as np\n",
        "\n",
        "from scipy.signal import hilbert\n",
        "import scipy.signal\n",
        "\n",
        "\n",
        "# Frequencies\n",
        "delta = (0.5, 4)\n",
        "theta = (4, 8)\n",
        "alpha = (8, 13)\n",
        "beta = (13, 30)\n",
        "gamma = (30, 45)\n",
        "freq_bands = [delta, theta, alpha, beta, gamma]\n",
        "# Loop over your array_3d data\n",
        "features = []\n",
        "for i in range(array_3d.shape[0]):  # iterating over the first dimension\n",
        "    # FFT on your data\n",
        "    freqs, psd = scipy.signal.welch(array_3d[i])\n",
        "    # Loop over the frequency bands and save power from each band\n",
        "    band_power = []\n",
        "    for band in freq_bands:\n",
        "        idx_band = np.logical_and(freqs >= band[0], freqs <= band[1])\n",
        "        power = sum(psd[idx_band])\n",
        "        band_power.append(power)\n",
        "    features.append(band_power)\n",
        "features = np.array(features)\n",
        "print(features.shape)\n",
        "real_features = np.abs(features)\n",
        "\n",
        "analytic_signal_features = hilbert(real_features)\n",
        "analytic_signal_features2=hilbert(array_3d)\n",
        "\n",
        "# # If you want to get the absolute envelope of this analytic signal, use:\n",
        "envelope_features = np.abs(analytic_signal_features)\n",
        "envelope_features2 = np.abs(analytic_signal_features2)\n",
        "\n",
        "print(envelope_features.shape)\n",
        "envelope=np.hstack((envelope_features, array_3d))\n",
        "\n",
        "feature=envelope\n",
        "# feature=envelope_features\n",
        "print(len(feature))\n",
        "feature_array=np.array(feature)\n",
        "X_n=feature_array\n",
        "print(X_n.shape)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
