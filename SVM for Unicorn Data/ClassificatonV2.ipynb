{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vMaBF4q9pl9k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import hilbert\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.signal import butter, filtfilt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.layers import Dense,  BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_name = input(\"Please enter the folder's name: \")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bvs0pSXWpl9m",
        "outputId": "554c9aa5-47a2-4247-da93-56e4cafad9d0"
      },
      "outputs": [],
      "source": [
        "# Define the column names\n",
        "column_names = ['FZ', 'FC1', 'FC2', 'C3', 'CZ', 'C4', 'CPZ', 'PZ', 'AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ',\n",
        "                'Battery', 'Sample', 'Unknown', 'Instruction', 'Female/Male', 'Outdoor/Indoor', 'Human Behavior']\n",
        "df = []\n",
        "if os.path.exists(folder_name) and os.path.isdir(folder_name):\n",
        "    for file_name in os.listdir(folder_name):\n",
        "        if file_name.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_name, file_name)\n",
        "            df_temp = pd.read_csv(file_path, header=None)\n",
        "            df.append(df_temp)     \n",
        "    combined_data_array_3d = np.array(df)\n",
        "    combined_data_array_2d= combined_data_array_3d.reshape(-1, 21)\n",
        "    \n",
        "Combined_raw_eeg = pd.DataFrame(combined_data_array_2d) \n",
        "Combined_raw_eeg.columns = column_names\n",
        "\n",
        "#Excluding the useless columns\n",
        "columns_to_remove = ['AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ', 'Battery', 'Sample', 'Unknown','Instruction','Female/Male', 'Outdoor/Indoor', 'Human Behavior']\n",
        "Combined_raw_eeg = Combined_raw_eeg.drop(columns=columns_to_remove, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "# Band pass filter\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "Combined_raw_eeg_bp = np.copy(Combined_raw_eeg)\n",
        "num_columns = Combined_raw_eeg_bp.shape[1]\n",
        "print(num_columns)\n",
        "for column in range(num_columns):\n",
        "    Combined_raw_eeg_bp[:, column] = butter_bandpass_filter(Combined_raw_eeg_bp[:, column], lowcut=.4, highcut=40, fs=250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-proccessing\n",
        "# Denoising \n",
        "def denoise_data(df, col_names, n_clusters):\n",
        "    df_denoised = df.copy()\n",
        "    for col_name, k in zip(col_names, n_clusters):\n",
        "        df_denoised[col_name] = pd.to_numeric(df_denoised[col_name], errors='coerce') # Convert column to numeric format\n",
        "        X = df_denoised.select_dtypes(include=['float64', 'int64']) # Select only numeric columns\n",
        "        clf = KNeighborsRegressor(n_neighbors=k, weights='uniform') # Fit KNeighborsRegressor\n",
        "        clf.fit(X.index.values[:, np.newaxis], X[col_name])\n",
        "        y_pred = clf.predict(X.index.values[:, np.newaxis]) # Predict values \n",
        "        df_denoised[col_name] = y_pred\n",
        "    return df_denoised\n",
        "\n",
        "# Z_scoring\n",
        "def z_score(df, col_names):\n",
        "    df_standard = df.copy()\n",
        "    for col in col_names:\n",
        "        df_standard[col] = (df[col] - df[col].mean()) / df[col].std()\n",
        "    return df_standard\n",
        "\n",
        "# Detrending\n",
        "def detrend(df, col_names):\n",
        "    df_detrended = df.copy()\n",
        "    for col in col_names:\n",
        "        y = df_detrended[col]\n",
        "        x = np.arange(len(y))\n",
        "        p = np.polyfit(x, y, 1)\n",
        "        trend = np.polyval(p, x)\n",
        "        detrended = y - trend\n",
        "        df_detrended[col] = detrended\n",
        "    return df_detrended\n",
        "\n",
        "def preprocess(df, col_names, n_clusters):\n",
        "    df_new = df.copy()\n",
        "    df_new = denoise_data(df, col_names, n_clusters)\n",
        "    df_new = z_score(df_new, col_names)\n",
        "    df_new = detrend(df_new, col_names)\n",
        "    return df_new\n",
        "\n",
        "Combined_raw_eeg_bp=pd.DataFrame(Combined_raw_eeg_bp)\n",
        "eeg_df_denoised = preprocess(Combined_raw_eeg_bp, col_names=list(Combined_raw_eeg_bp.columns), n_clusters=[50]*len(Combined_raw_eeg_bp.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lableing\n",
        "column_indices = {'Instruction': 17, 'Female/Male': 18, 'Outdoor/Indoor': 19}\n",
        "selected_columns = [column_indices['Instruction'], column_indices['Female/Male'], column_indices['Outdoor/Indoor']]\n",
        "data_im_ins = combined_data_array_2d[:, selected_columns]\n",
        "denoised_im_ins = np.concatenate((eeg_df_denoised, data_im_ins), axis=1)\n",
        "\n",
        "# Check the third last column (column 9) and keep rows if column 9 is equal to 1\n",
        "filtered_denoised_im_ins = denoised_im_ins[(denoised_im_ins[:, -3] == denoised_im_ins[:, -2]) | (denoised_im_ins[:, -3] == denoised_im_ins[:, -1])]\n",
        "filtered_denoised_im_ins_df = pd.DataFrame(filtered_denoised_im_ins)\n",
        "\n",
        "# Create a new column 'event'\n",
        "filtered_denoised_im_ins_df['event'] = ''\n",
        "for index, row in filtered_denoised_im_ins_df.iterrows():\n",
        "    if row.iloc[-4] == 'F' or row.iloc[-4] == 'M':\n",
        "        filtered_denoised_im_ins_df.at[index, 'event'] = '0'\n",
        "    else:  #elif row.iloc[-4] == 'I' or row.iloc[-4] == 'O' or row.iloc[-4] == 'S':\n",
        "        filtered_denoised_im_ins_df.at[index, 'event'] = '1'\n",
        "        \n",
        "selected_data = filtered_denoised_im_ins_df.iloc[:, :8]  \n",
        "lable=filtered_denoised_im_ins_df.iloc[:, -1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "lable=filtered_denoised_im_ins_df.iloc[:, -1:]\n",
        "lable.to_csv('lable.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(364500, 8)\n"
          ]
        }
      ],
      "source": [
        "print(selected_data.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Windowing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "win_size = 250\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(0, len(selected_data), win_size):\n",
        "    window_data = selected_data.iloc[i:i+win_size]\n",
        "    window_label = lable.iloc[i:i+win_size]\n",
        "    X.append(window_data)\n",
        "    y.append(window_label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X, y = shuffle(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1458, 2000)\n",
            "(1458, 250, 8)\n"
          ]
        }
      ],
      "source": [
        "array_3d = X.reshape(X.shape[0], 250*8)\n",
        "print(array_3d.shape)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1458\n",
            "(1458, 256)\n"
          ]
        }
      ],
      "source": [
        "# Hilbert feature extraction and PCA data Reduction\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "scaler = StandardScaler()\n",
        "feature=[]\n",
        "for chunk in X:\n",
        "    analytic_signal = hilbert(chunk)\n",
        "    envelope = np.abs(analytic_signal)\n",
        "    envelope=np.hstack((envelope, chunk))\n",
        "    envelop_standardized = scaler.fit_transform(envelope)\n",
        "    envelop_standardized_tr=envelop_standardized.transpose()\n",
        "    pca = PCA(n_components=16)  # how many components you want to keep\n",
        "    pca.fit(envelop_standardized_tr)\n",
        "    eeg_data_pca = pca.transform(envelop_standardized_tr)\n",
        "    # print(eeg_data_pca.shape)\n",
        "    feature.append(eeg_data_pca)\n",
        "print(len(feature))\n",
        "feature_array=np.array(feature)\n",
        "X_n=feature_array.reshape(-1,16*16)\n",
        "print(X_n.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_n=np.squeeze(y[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1458, 256) (1458,)\n"
          ]
        }
      ],
      "source": [
        "print(X_n.shape, y_n.shape)\n",
        "\n",
        "# Balance the dataset\n",
        "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X_n, y_n)\n",
        "X_resampled= X_resampled.astype(np.float32)\n",
        "y_resampled = y_resampled.astype(np.int32)\n",
        "\n",
        "# Split X and y into training and testing sets\n",
        "X_touched, X_untouch, y_touch, y_untouch = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_touched, y_touch, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert y_train and y_test to categorical format for Keras\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "y_untouch=tf.keras.utils.to_categorical(y_untouch, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(944,) (236,)\n"
          ]
        }
      ],
      "source": [
        "# Convert one-hot-encoded labels to integer-encoded labels\n",
        "y_train = np.argmax(y_train, axis=-1)\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_untouch = np.argmax(y_untouch, axis=-1)\n",
        "\n",
        "print(y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (944, 256) y_train: (944,) X_test: (236, 256) y_test: (236,) X_untouch: (296, 256) y_untouch: (296,)\n"
          ]
        }
      ],
      "source": [
        "print('X_train:', X_train.shape, 'y_train:', y_train.shape, 'X_test:', X_test.shape, 'y_test:',\n",
        "      y_test.shape, 'X_untouch:', X_untouch.shape, 'y_untouch:', y_untouch.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy:  0.4745762711864407\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.49      0.48       116\n",
            "           1       0.48      0.46      0.47       120\n",
            "\n",
            "    accuracy                           0.47       236\n",
            "   macro avg       0.47      0.47      0.47       236\n",
            "weighted avg       0.47      0.47      0.47       236\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from joblib import dump\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "# Create a linear SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "# Save the model to disk\n",
        "filename = 'C:/Users/tnlab/OneDrive/Documents/GitHub/AlphaFold/Neurofeedback-Based-BCI/my_svm_model.joblib'\n",
        "dump(clf, filename)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print('Model accuracy: ', accuracy_score(y_test, y_pred))\n",
        "report_svm_matrix = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report_svm_matrix)\n",
        "report_svm = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "report_df_svm = pd.DataFrame(report_svm).transpose()\n",
        "report_df_svm.to_excel(f\"svm_classification_report_{folder_name}.xlsx\", index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
